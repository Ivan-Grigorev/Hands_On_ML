{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f39af4-3108-4e03-9c27-4e9b08031eea",
   "metadata": {},
   "source": [
    "<h1>Chapter 08. Dimensionality Reduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ede889-0a0e-4ce0-b3f6-6d89eae4c280",
   "metadata": {},
   "source": [
    "Dimensionality reduction is a technique used in machine learning and data analysis to reduce the number of input variables or features in a dataset while preserving essential information. It aims to simplify complex datasets by transforming them into a lower-dimensional space, making them more manageable for analysis and modeling. Dimensionality reduction methods seek to retain as much relevant information as possible while reducing the computational complexity and noise in the data, facilitating tasks such as visualization, clustering, and classification. Popular techniques include Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE), and Linear Discriminant Analysis (LDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93f8bf-4850-42a6-9b62-ca006b57bad4",
   "metadata": {},
   "source": [
    "<h2>PCA</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56205eb3-ad35-4295-924c-37c193f5e812",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) is a dimensionality reduction technique that simplifies high-dimensional datasets by identifying and representing patterns using fewer variables while preserving essential information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7e9a5-a970-44aa-9858-1519528b081c",
   "metadata": {},
   "source": [
    "Let's build a simple 3D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85c3ce0-82ed-472b-8749-d403595d9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "m = 60  # number of samples\n",
    "\n",
    "# Define weights and noise level\n",
    "w1, w2 = 0.1, 0.3\n",
    "noise = 0.1\n",
    "\n",
    "# Generate random angles\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "\n",
    "# Create an empty array to store data\n",
    "X = np.empty((m, 3))\n",
    "\n",
    "# Generate features using trigonometric functions and noise\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles) / 2 + noise * np.random.randn(m) / 2\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cba58-ffd6-47b5-aed5-ace6f1e656c2",
   "metadata": {},
   "source": [
    "<h3>Principal Components</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042370ec-f432-455d-b718-1b2c2489b152",
   "metadata": {},
   "source": [
    "Principal Components (PCs) are the main underlying patterns in data discovered through PCA, representing directions of maximum variance. They provide a new coordinate system where each component is a combination of original features. PCs aid in dimensionality reduction, visualization, and data compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb26f00-0331-4403-8f3d-2816746e4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)\n",
    "\n",
    "# Perform Singular Value Decomposition (SVD) on the centered data\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "\n",
    "c1 = Vt.T[:, 0]\n",
    "c2 = Vt.T[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fededa-857f-4945-95be-31badbe2c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "S = np.zeros(X_centered.shape)\n",
    "S[:n, :n] = np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c4e84d-358a-4dde-a416-a5c0e6a19fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X_centered, U.dot(S).dot(Vt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40068fe0-db41-4130-bf75-51b57deb4fd0",
   "metadata": {},
   "source": [
    "<h3>Projecting down to <i>d</i> Dimensions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1a7f6-c008-405c-baf4-e720b19af9e2",
   "metadata": {},
   "source": [
    "Projecting down to `d` dimensions involves transforming high-dimensional data into a lower-dimensional space while preserving essential information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8e64cd-7234-43ca-a87a-acb497f1ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]\n",
    "X2D = X_centered.dot(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ad1b3f-35e9-456a-be3b-7b9327592b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2D_using_svd = X2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94459ce1-5cff-46ba-ad7e-f9ecb0a81fc5",
   "metadata": {},
   "source": [
    "<h3>Using Scikit-Learn</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6a3c8-b863-41b0-97dd-856bbd291e02",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) from scikit-learn is a dimensionality reduction technique that identifies the main patterns in data, allowing for the transformation of high-dimensional datasets into a lower-dimensional space while retaining critical information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3383290-1a50-45ad-9b86-c7ed3224ea8c",
   "metadata": {},
   "source": [
    "With Scikit-Learn, PCA is really trivial. It even takes care of mean centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b68af5-a12c-4eea-82d5-f68701a93b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445cbc0d-db6e-43b8-9fc5-76c63d99894c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26203346,  0.42067648],\n",
       "       [-0.08001485, -0.35272239],\n",
       "       [ 1.17545763,  0.36085729],\n",
       "       [ 0.89305601, -0.30862856],\n",
       "       [ 0.73016287, -0.25404049]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5681a8-ea43-4d88-aba9-c2969ab3c30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26203346, -0.42067648],\n",
       "       [ 0.08001485,  0.35272239],\n",
       "       [-1.17545763, -0.36085729],\n",
       "       [-0.89305601,  0.30862856],\n",
       "       [-0.73016287,  0.25404049]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D_using_svd[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c316531-46c1-447c-a633-52209f49cb79",
   "metadata": {},
   "source": [
    "Running PCA multiple times on slightly different datasets may result in different results. In general the only difference is that some axes may be flipped. In this example, PCA using Scikit-Learn gives the same projection as the one given by the SVD approach, except both axes are flipped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d0f0ab-9fce-4ac5-ba8b-c8a7f63610c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X2D, -X2D_using_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ea0c7-f222-46b0-98ea-049fab842063",
   "metadata": {},
   "source": [
    "Recover the 3D points projected on the plane (PCA 2D subspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2e8e5c-273e-4f97-aed5-b249653876fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3D_inv = pca.inverse_transform(X2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce719ca-60dc-4a5a-af47-5a2a747356f4",
   "metadata": {},
   "source": [
    "There was some loss of information during the projection step, so the recovered 3D points are not exactly equal to the original 3D points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7c3940-9a4a-499d-a795-c9b03b6a93ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X3D_inv, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ac1e3-c0d9-471a-903f-25ca3c295088",
   "metadata": {},
   "source": [
    "Reconstruction error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "469e2f81-4c81-403c-a843-ffd3e4fc0a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01017033779284855"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sum(np.square(X3D_inv - X), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc57dbc-fed6-4cf8-a102-c7e0df40a0c5",
   "metadata": {},
   "source": [
    "The inverse transform in the SVD approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "911cfbce-fc36-4067-a422-43a75f326868",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3D_inv_using_svd = X2D_using_svd.dot(Vt[:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f29fe-e9c5-4847-8ea8-8f109064b2ef",
   "metadata": {},
   "source": [
    "The reconstructions from both methods differ because Scikit-Learn's `PCA` class automatically handles reversing the mean centering. However, subtracting the mean manually results in identical reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c5fe17-4be9-4e94-adbb-e7b75135c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X3D_inv_using_svd, X3D_inv - pca.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ea941-e5d9-4c47-9422-788cbdcbde60",
   "metadata": {},
   "source": [
    "The `PCA` object gives access to the principal components that it computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cddd1c06-1f72-4713-b365-e1702a8c4d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93636116, -0.29854881, -0.18465208],\n",
       "       [ 0.34027485, -0.90119108, -0.2684542 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826212ce-5679-4f94-b6f0-7e1f769a6fa8",
   "metadata": {},
   "source": [
    "<h3>Explained Variance Ratio</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7194a-7ce5-4b51-a7d1-05675ae89acb",
   "metadata": {},
   "source": [
    "Explained Variance Ratio quantifies the proportion of dataset variance captured by each principal component in PCA, aiding in understanding the significance of individual components for data representation and dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53ffb553-c14b-4f50-a4b9-a2403d42c9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84248607, 0.14631839])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdead619-f10b-447d-98e3-3e9c6dd99045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011195535570688975"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15bc3dc-e21d-40d3-a019-ad16eb3e2f8f",
   "metadata": {},
   "source": [
    "The result suggests that 84.2% of the variance of the dataset lies along the first axis, and 14.6% lies along the second axis. The third axis remains less than 1.2%, which means it carries little information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
