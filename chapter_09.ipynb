{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99273db-ad23-42e0-98f3-5820dc8d9379",
   "metadata": {},
   "source": [
    "<h1>Chapter 09. Up and Running with TensorFlow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493c2cf-579b-42c9-9322-b0b7bf36413a",
   "metadata": {},
   "source": [
    "**TensorFlow** is an open-source machine learning framework developed by Google Brain for building and training various types of machine learning models, including deep learning neural networks. It provides a comprehensive ecosystem of tools, libraries, and resources for tasks such as data preprocessing, model building, training, deployment, and inference. TensorFlow supports both CPU and GPU computations, allowing for efficient processing of large-scale datasets and complex models. It's widely used in research, industry, and academia for a diverse range of machine learning and artificial intelligence applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894a72e-2043-4b10-961f-5bb219e4e00e",
   "metadata": {},
   "source": [
    "<h2>Creating and Running a first Graph</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43fc88-f074-498e-b4bb-2ea6c3ab2d8c",
   "metadata": {},
   "source": [
    "Creating a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39913489-39ed-4611-a56c-1ffa68e47df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow version 1 compatibility module as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "# Disable eager execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# Define TensorFlow variables with initial values\n",
    "x = tf.Variable(initial_value=3, name='x')\n",
    "y = tf.Variable(initial_value=4, name='y')\n",
    "\n",
    "# Define computational graph\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5421cb-0f18-421a-823e-6ac59ef71349",
   "metadata": {},
   "source": [
    "To run the graph, a TensorFlow session must be opened and used to initialize variables and evaluate `f`. The following code creates a session, initializes variables, computes `f`, and closes the session (freeing resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2780bd-d2ed-4789-a314-7bab30be48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 17:27:10.032256: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()  # create session\n",
    "\n",
    "sess.run(x.initializer)  # initialize x\n",
    "sess.run(y.initializer)  # initialize y\n",
    "\n",
    "result = sess.run(f)  # execute the computation f\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9e751e-3e01-4e9c-8d1e-ab6201fa82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59a23d-91b0-4978-9cfb-df7815bb7eb1",
   "metadata": {},
   "source": [
    "Rather than individually executing the initializer for each variable, it is more efficiant to utilize `global_variables_initializer()`. Repeatedly calling `sess.run` for initialization can become cumbersome; however, there exists a more streamlined approach: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc59f03-6ab1-41a8-8292-32f244dfcae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f0294-39f9-4935-be2a-a8dbf4f279bd",
   "metadata": {},
   "source": [
    "`InteractiveSession()` in TensorFlow allows you to work interactively, seamlessly combining graph and execution without needing a `with` block. It's convenient for interactive environments like Jupyter notebooks, but remember to close the session manually to free up resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ea6148-19a3-4903-a881-3cad6c7f5bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init.run()\n",
    "result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b14eae-fa97-4b23-b480-e22fd6dd807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8826cd-b13d-4e8f-ad46-7b4edf1bd389",
   "metadata": {},
   "source": [
    "<h2>Managing Graphs</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17201d62-37dc-4c6d-b757-f8edbb1f3f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the default TensorFlow graph to clear\n",
    "# any previously defined operations or variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d862b5-dc7c-4bd5-9ec5-d017b08a561d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f2a0328-e324-4afa-8571-dd47c939783b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aac545-99d6-4007-a48f-60fdabf0b648",
   "metadata": {},
   "source": [
    "<h2>Lifecycle of a Node Value</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd625b5a-4201-42c1-ad98-238d84ed1b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767e381a-07cf-4eb2-9e04-6ecee63c2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b03bbc-4163-4eb2-9167-ecb46eece33a",
   "metadata": {},
   "source": [
    "<h2>Linear Rergression with TensorFlow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7703c-5a9f-44e6-a718-a9c6394d3d3e",
   "metadata": {},
   "source": [
    "The code below manipulates two-dimensional arrays to perform linear regression on a dataset containing California real estate prices. The code starts by retrieving a dataset. It then adds an additional input bias feature to all training samples using NumPy. The code then creates two TensorFlow constant nodes, `X` and `y`, to store this data and targets, and then uses a series of matrix operations provided by TensorFlow to determine theta. Such matrix functions are `transpose()`, `matmul()` and `matrix_inverse()` does not perform calculations immediately; instead, nodes are created in the graph that will be executed when the graph is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec77a1f2-0364-4e1a-be8e-c45ef666e264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7174683e+01],\n",
       "       [ 4.3591911e-01],\n",
       "       [ 9.3909204e-03],\n",
       "       [-1.0637519e-01],\n",
       "       [ 6.4145899e-01],\n",
       "       [-4.1128196e-06],\n",
       "       [-3.7799443e-03],\n",
       "       [-4.2388692e-01],\n",
       "       [-4.3728542e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(\n",
    "    housing_data_plus_bias,\n",
    "    dtype=tf.float32,\n",
    "    name='X'\n",
    ")\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1),\n",
    "    dtype=tf.float32,\n",
    "    name='y'\n",
    ")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede0cdc-c772-41b8-82d4-797c07b905be",
   "metadata": {},
   "source": [
    "Compare with pure NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6547fd22-d992-476e-9acf-d2c09346709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfee51b-7666-437c-bc9f-d2f666b89541",
   "metadata": {},
   "source": [
    "Compare with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7009cc3d-1348-4387-b5f3-4162469acb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c714aa-dfec-46dc-8f01-fa6bc800b4a7",
   "metadata": {},
   "source": [
    "<h2>Implementation of Gradient Descent</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fc738-42b8-4731-813c-071f824dbee0",
   "metadata": {},
   "source": [
    "Gradient Descent requires scaling the feature vectors first. This can be achieved using the `StandardScaler` from Scikit-Learn. The `StandardScaler` scales features by removing the mean and scaling to unit variance, which helps improve the performance of Gradient Descent algorithms by ensuring that all features have a similar scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de1a08b-5f52-442e-b1d0-f075bc7478a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067ce1e5-578e-4e85-b5d8-3eeecce59bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  6.60969987e-17,  5.50808322e-18,  6.60969987e-17,\n",
       "       -1.06030602e-16, -1.10161664e-17,  3.44255201e-18, -1.07958431e-15,\n",
       "       -8.52651283e-15])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean value of each feature (column)\n",
    "scaled_housing_data_plus_bias.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a65769f4-39f8-443a-9713-625dc950b5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38915536,  0.36424355,  0.5116157 , ..., -0.06612179,\n",
       "       -0.06360587,  0.01359031])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean value of each instance (row)\n",
    "scaled_housing_data_plus_bias.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45f5f4bd-36ac-4aff-8fe3-3453d8f5a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11111111111111005"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the overall mean value of all elements\n",
    "scaled_housing_data_plus_bias.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6223a47e-041d-4da5-8c6b-feebf0b67802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_housing_data_plus_bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b716-5b8e-4f53-b7f6-cee7ad3b1c2b",
   "metadata": {},
   "source": [
    "<h3>Manually computing the Gradients</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7731b349-a893-4e5a-8e4f-195e31cd5dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.6322219371795654\n",
      "Epoch 200 MSE = 0.5727803111076355\n",
      "Epoch 300 MSE = 0.5585008263587952\n",
      "Epoch 400 MSE = 0.5490700006484985\n",
      "Epoch 500 MSE = 0.5422880053520203\n",
      "Epoch 600 MSE = 0.5373790860176086\n",
      "Epoch 700 MSE = 0.5338220000267029\n",
      "Epoch 800 MSE = 0.5312425494194031\n",
      "Epoch 900 MSE = 0.5293705463409424\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(\n",
    "    scaled_housing_data_plus_bias,\n",
    "    dtype=tf.float32,\n",
    "    name='X'\n",
    ")\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1),\n",
    "    dtype=tf.float32,\n",
    "    name='y'\n",
    ")\n",
    "\n",
    "# random_uniform() creates a node in the graph that will generate a tensor\n",
    "# containing random values with a given shape and range\n",
    "theta = tf.Variable(tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name='theta')\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "# Create a node that will assign a new value to the variable\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Loop repeatedly executes the learning step and\n",
    "    # otputs the MSE each 100 iterations\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        \n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c671c80-014b-47f2-b821-b321ac554d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855226e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44081801e-04],\n",
       "       [-3.91945131e-02],\n",
       "       [-8.61356556e-01],\n",
       "       [-8.23479712e-01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c30b19-2294-42c9-a61d-6e635e593fad",
   "metadata": {},
   "source": [
    "<h3>Using autodiff</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cc8603a-c39d-4c61-ad50-1103d8b3a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(\n",
    "    scaled_housing_data_plus_bias,\n",
    "    dtype=tf.float32,\n",
    "    name='X'\n",
    ")\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1),\n",
    "    dtype=tf.float32,\n",
    "    name='y'\n",
    ")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637145db-adc5-4d51-9b3a-6ce5e3ce8173",
   "metadata": {},
   "source": [
    "The `tf.gradients()` function takes the `mse` operation and `theta` variable list and creates a list of operations (one per variable) to compute the gradients of the operation with respect to each variable. Thus, the gradients node will compute the vector gradient of the MSE with respect to theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4921c80-106c-4df2-8a11-36ade2870ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(ys=mse, xs=[theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "670fa556-9ef4-4c77-85f2-68390b7099eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.6322218775749207\n",
      "Epoch 200 MSE = 0.5727803111076355\n",
      "Epoch 300 MSE = 0.5585008263587952\n",
      "Epoch 400 MSE = 0.5490700006484985\n",
      "Epoch 500 MSE = 0.5422880053520203\n",
      "Epoch 600 MSE = 0.5373790860176086\n",
      "Epoch 700 MSE = 0.5338219404220581\n",
      "Epoch 800 MSE = 0.5312425494194031\n",
      "Epoch 900 MSE = 0.5293704867362976\n",
      "\n",
      "Best theta:\n",
      "[[ 2.06855249e+00]\n",
      " [ 7.74078071e-01]\n",
      " [ 1.31192386e-01]\n",
      " [-1.17845066e-01]\n",
      " [ 1.64778143e-01]\n",
      " [ 7.44078017e-04]\n",
      " [-3.91945094e-02]\n",
      " [-8.61356676e-01]\n",
      " [-8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        \n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(f\"\\nBest theta:\\n{best_theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b659d-72e4-4eb8-8837-702c2bfb68bc",
   "metadata": {},
   "source": [
    "<h3>Using a <code>GradientDescentOptimizer</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227b1ea-19dd-450f-bbf5-b0afb5b31a7d",
   "metadata": {},
   "source": [
    "The `GradientDescentOptimizer` is an optimization algorithm that iteratively adjusts the parameters (weights) of a model in the direction of the steepest descent of the loss function. It updates the parameters based on the gradients of the loss function with respect to the parameters, scaled by a learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e6478ca-52ed-46be-92ec-48f95b9aafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(\n",
    "    scaled_housing_data_plus_bias,\n",
    "    dtype=tf.float32,\n",
    "    name='X'\n",
    ")\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1),\n",
    "    dtype=tf.float32,\n",
    "    name='y'\n",
    ")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228476fa-e8bf-4f26-86ac-ec222c872ea6",
   "metadata": {},
   "source": [
    "Replace `gradients = ...` and `training_op = ...` with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "134799ca-8a35-4881-b4a3-472801ef3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)  # minimize the mean squared error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0c611e0-7dcd-4075-968f-20ec6070d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.6322218775749207\n",
      "Epoch 200 MSE = 0.5727803111076355\n",
      "Epoch 300 MSE = 0.5585008263587952\n",
      "Epoch 400 MSE = 0.5490700006484985\n",
      "Epoch 500 MSE = 0.5422880053520203\n",
      "Epoch 600 MSE = 0.5373790860176086\n",
      "Epoch 700 MSE = 0.5338219404220581\n",
      "Epoch 800 MSE = 0.5312425494194031\n",
      "Epoch 900 MSE = 0.5293704867362976\n",
      "\n",
      "Best theta:\n",
      "[[ 2.06855249e+00]\n",
      " [ 7.74078071e-01]\n",
      " [ 1.31192386e-01]\n",
      " [-1.17845066e-01]\n",
      " [ 1.64778143e-01]\n",
      " [ 7.44078017e-04]\n",
      " [-3.91945094e-02]\n",
      " [-8.61356676e-01]\n",
      " [-8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        \n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(f\"\\nBest theta:\\n{best_theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36454042-8c89-44f1-b5c6-38a4b43fe121",
   "metadata": {},
   "source": [
    "<h3>Using a <code>MomentumOptimizer</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0663d2-6dbd-4d57-8a11-e9f2cdb48630",
   "metadata": {},
   "source": [
    "The `MomentumOptimizer` is an optimization algorithm that enhances the basic gradient descent method by incorporating momentum. It accumulates a weighted average of past gradients and uses this information to update the parameters (weights) of a model. This helps to accelerate convergence, especially in the presence of high curvature or noisy gradients. The momentum parameter controls the influence of past gradients on the parameter updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03e54467-563d-45c9-8c86-daf726be4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(\n",
    "    scaled_housing_data_plus_bias,\n",
    "    dtype=tf.float32,\n",
    "    name='X'\n",
    ")\n",
    "y = tf.constant(\n",
    "    housing.target.reshape(-1, 1),\n",
    "    dtype=tf.float32,\n",
    "    name='y'\n",
    ")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd7ef323-a43d-4a30-9430-7a8127e7fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set momentum parameter to 0.9, which controls the influence\n",
    "# of past gradients on the parameter updates\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eea511be-2d63-4d39-b268-c4a409df1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.5273160338401794\n",
      "Epoch 200 MSE = 0.5244147777557373\n",
      "Epoch 300 MSE = 0.5243281722068787\n",
      "Epoch 400 MSE = 0.5243218541145325\n",
      "Epoch 500 MSE = 0.5243210792541504\n",
      "Epoch 600 MSE = 0.5243210196495056\n",
      "Epoch 700 MSE = 0.5243209600448608\n",
      "Epoch 800 MSE = 0.5243209600448608\n",
      "Epoch 900 MSE = 0.5243209600448608\n",
      "\n",
      "Best theta:\n",
      "[[ 2.068558  ]\n",
      " [ 0.8296167 ]\n",
      " [ 0.11875112]\n",
      " [-0.26552212]\n",
      " [ 0.30569226]\n",
      " [-0.00450316]\n",
      " [-0.03932616]\n",
      " [-0.8998917 ]\n",
      " [-0.87054664]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        \n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(f\"\\nBest theta:\\n{best_theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f3e28-98f5-41bf-9fc5-56b7453ee779",
   "metadata": {},
   "source": [
    "<h2>Feeding Data to the Training Algorithm</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083fb5e-72e2-4d02-9c41-c5ad478814b0",
   "metadata": {},
   "source": [
    "The `tf.placeholder()` function in TensorFlow is used to create a placeholder tensor. Placeholder tensors are used as input points for feeding actual data into a TensorFlow computational graph during the execution phase. They act as empty nodes that will be filled with actual data when a session runs the computational graph. Placeholders allow for dynamic data input, making TensorFlow models more flexible and adaptable to different datasets and scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba9dfd44-bb23-4d41-b394-633992407615",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "A = tf.placeholder(dtype=tf.float32, shape=(None, 3))  # None for any size measurement\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bcc2640-5399-4c29-bd8c-8146b57f70c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90345027-8f6e-4c56-94d9-d4370f7db6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a53db-8212-4159-9047-6c3eccfd380b",
   "metadata": {},
   "source": [
    "<h3>Mini-batch Gradient Descent</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c03bd8d-1f7f-4eef-964b-9328917a9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Set X and y as placeholders\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define tha packet size and calculate the totla number of packets\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5d8a4-bfa7-4fe5-8d7a-a284e0c05eff",
   "metadata": {},
   "source": [
    "Finally, at runtime, one extracts the mini-batches one by one and provides the value of X and y through the feed_dict parameter when evaluating a node that depends on either of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60b91ace-d384-4c6f-bed2-e38e52ade348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0714476 ],\n",
       "       [ 0.8462012 ],\n",
       "       [ 0.11558535],\n",
       "       [-0.26835832],\n",
       "       [ 0.32982782],\n",
       "       [ 0.00608358],\n",
       "       [ 0.07052915],\n",
       "       [-0.87988573],\n",
       "       [-0.8634251 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01921ee9-12e6-4c27-8840-4382474daf59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
