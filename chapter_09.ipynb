{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99273db-ad23-42e0-98f3-5820dc8d9379",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h1>Chapter 09. Up and Running with TensorFlow</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493c2cf-579b-42c9-9322-b0b7bf36413a",
   "metadata": {},
   "source": [
    "**TensorFlow** is an open-source machine learning framework developed by Google Brain for building and training various types of machine learning models, including deep learning neural networks. It provides a comprehensive ecosystem of tools, libraries, and resources for tasks such as data preprocessing, model building, training, deployment, and inference. TensorFlow supports both CPU and GPU computations, allowing for efficient processing of large-scale datasets and complex models. It's widely used in research, industry, and academia for a diverse range of machine learning and artificial intelligence applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894a72e-2043-4b10-961f-5bb219e4e00e",
   "metadata": {},
   "source": [
    "<h2>Creating and Running a first Graph</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62a9b7-6f44-42ac-9137-e4f29d2d406a",
   "metadata": {},
   "source": [
    "In TensorFlow, a graph represents the computation workflow of a machine learning model. It consists of nodes that represent operations (such as mathematical computations or data transformations) and edges that represent the flow of data between these operations. The graph defines the dependencies between operations, allowing TensorFlow to efficiently execute them in the correct order and optimize the computation for performance. Graphs can be constructed using TensorFlow's high-level APIs or by directly manipulating TensorFlow's computational graph using low-level operations. They serve as a foundational structure for defining, training, and executing machine learning models in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a944d-3745-4fb4-999b-c7580670233c",
   "metadata": {},
   "source": [
    "Creating a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39913489-39ed-4611-a56c-1ffa68e47df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow version 1 compatibility module as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# Disable eager execution\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# Define TensorFlow variables with initial values\n",
    "x = tf.Variable(initial_value=3, name=\"x\")\n",
    "y = tf.Variable(initial_value=4, name=\"y\")\n",
    "\n",
    "# Define computational graph\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5421cb-0f18-421a-823e-6ac59ef71349",
   "metadata": {},
   "source": [
    "To run the graph, a TensorFlow session must be opened and used to initialize variables and evaluate `f`. The following code creates a session, initializes variables, computes `f`, and closes the session (freeing resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2780bd-d2ed-4789-a314-7bab30be48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 11:43:26.018988: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()  # create session\n",
    "\n",
    "sess.run(x.initializer)  # initialize x\n",
    "sess.run(y.initializer)  # initialize y\n",
    "\n",
    "result = sess.run(f)  # execute the computation f\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9e751e-3e01-4e9c-8d1e-ab6201fa82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59a23d-91b0-4978-9cfb-df7815bb7eb1",
   "metadata": {},
   "source": [
    "Rather than individually executing the initializer for each variable, it is more efficiant to utilize `global_variables_initializer()`. Repeatedly calling `sess.run` for initialization can become cumbersome; however, there exists a more streamlined approach: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc59f03-6ab1-41a8-8292-32f244dfcae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f0294-39f9-4935-be2a-a8dbf4f279bd",
   "metadata": {},
   "source": [
    "`InteractiveSession()` in TensorFlow allows you to work interactively, seamlessly combining graph and execution without needing a `with` block. It's convenient for interactive environments like Jupyter notebooks, but remember to close the session manually to free up resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ea6148-19a3-4903-a881-3cad6c7f5bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init.run()\n",
    "result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b14eae-fa97-4b23-b480-e22fd6dd807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8826cd-b13d-4e8f-ad46-7b4edf1bd389",
   "metadata": {},
   "source": [
    "<h2>Managing Graphs</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17201d62-37dc-4c6d-b757-f8edbb1f3f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the default TensorFlow graph to clear\n",
    "# any previously defined operations or variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4d862b5-dc7c-4bd5-9ec5-d017b08a561d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f2a0328-e324-4afa-8571-dd47c939783b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aac545-99d6-4007-a48f-60fdabf0b648",
   "metadata": {},
   "source": [
    "<h2>Lifecycle of a Node Value</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd625b5a-4201-42c1-ad98-238d84ed1b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767e381a-07cf-4eb2-9e04-6ecee63c2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b03bbc-4163-4eb2-9167-ecb46eece33a",
   "metadata": {},
   "source": [
    "<h2>Linear Rergression with TensorFlow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7703c-5a9f-44e6-a718-a9c6394d3d3e",
   "metadata": {},
   "source": [
    "The code below manipulates two-dimensional arrays to perform linear regression on a dataset containing California real estate prices. The code starts by retrieving a dataset. It then adds an additional input bias feature to all training samples using NumPy. The code then creates two TensorFlow constant nodes, `X` and `y`, to store this data and targets, and then uses a series of matrix operations provided by TensorFlow to determine theta. Such matrix functions are `transpose()`, `matmul()` and `matrix_inverse()` does not perform calculations immediately; instead, nodes are created in the graph that will be executed when the graph is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec77a1f2-0364-4e1a-be8e-c45ef666e264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7174683e+01],\n",
       "       [ 4.3591911e-01],\n",
       "       [ 9.3909204e-03],\n",
       "       [-1.0637519e-01],\n",
       "       [ 6.4145899e-01],\n",
       "       [-4.1128196e-06],\n",
       "       [-3.7799443e-03],\n",
       "       [-4.2388692e-01],\n",
       "       [-4.3728542e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede0cdc-c772-41b8-82d4-797c07b905be",
   "metadata": {},
   "source": [
    "Compare with pure NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6547fd22-d992-476e-9acf-d2c09346709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfee51b-7666-437c-bc9f-d2f666b89541",
   "metadata": {},
   "source": [
    "Compare with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7009cc3d-1348-4387-b5f3-4162469acb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654265e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c714aa-dfec-46dc-8f01-fa6bc800b4a7",
   "metadata": {},
   "source": [
    "<h2>Implementation of Gradient Descent</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fc738-42b8-4731-813c-071f824dbee0",
   "metadata": {},
   "source": [
    "Gradient Descent requires scaling the feature vectors first. This can be achieved using the `StandardScaler` from Scikit-Learn. The `StandardScaler` scales features by removing the mean and scaling to unit variance, which helps improve the performance of Gradient Descent algorithms by ensuring that all features have a similar scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de1a08b-5f52-442e-b1d0-f075bc7478a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067ce1e5-578e-4e85-b5d8-3eeecce59bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  6.60969987e-17,  5.50808322e-18,  6.60969987e-17,\n",
       "       -1.06030602e-16, -1.10161664e-17,  3.44255201e-18, -1.07958431e-15,\n",
       "       -8.52651283e-15])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean value of each feature (column)\n",
    "scaled_housing_data_plus_bias.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a65769f4-39f8-443a-9713-625dc950b5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38915536,  0.36424355,  0.5116157 , ..., -0.06612179,\n",
       "       -0.06360587,  0.01359031])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean value of each instance (row)\n",
    "scaled_housing_data_plus_bias.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45f5f4bd-36ac-4aff-8fe3-3453d8f5a46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11111111111111005"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the overall mean value of all elements\n",
    "scaled_housing_data_plus_bias.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6223a47e-041d-4da5-8c6b-feebf0b67802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_housing_data_plus_bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b716-5b8e-4f53-b7f6-cee7ad3b1c2b",
   "metadata": {},
   "source": [
    "<h3>Manually computing the Gradients</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7731b349-a893-4e5a-8e4f-195e31cd5dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.6322219371795654\n",
      "Epoch 200 MSE = 0.5727803111076355\n",
      "Epoch 300 MSE = 0.5585008263587952\n",
      "Epoch 400 MSE = 0.5490700006484985\n",
      "Epoch 500 MSE = 0.5422880053520203\n",
      "Epoch 600 MSE = 0.5373790860176086\n",
      "Epoch 700 MSE = 0.5338220000267029\n",
      "Epoch 800 MSE = 0.5312425494194031\n",
      "Epoch 900 MSE = 0.5293705463409424\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "# random_uniform() creates a node in the graph that will generate a tensor\n",
    "# containing random values with a given shape and range\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name=\"theta\"\n",
    ")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "# Create a node that will assign a new value to the variable\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Loop repeatedly executes the learning step and\n",
    "    # otputs the MSE each 100 iterations\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c671c80-014b-47f2-b821-b321ac554d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855226e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44081801e-04],\n",
       "       [-3.91945131e-02],\n",
       "       [-8.61356556e-01],\n",
       "       [-8.23479712e-01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c30b19-2294-42c9-a61d-6e635e593fad",
   "metadata": {},
   "source": [
    "<h3>Using autodiff</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cc8603a-c39d-4c61-ad50-1103d8b3a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name=\"theta\"\n",
    ")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637145db-adc5-4d51-9b3a-6ce5e3ce8173",
   "metadata": {},
   "source": [
    "The `tf.gradients()` function takes the `mse` operation and `theta` variable list and creates a list of operations (one per variable) to compute the gradients of the operation with respect to each variable. Thus, the gradients node will compute the vector gradient of the MSE with respect to theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4921c80-106c-4df2-8a11-36ade2870ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(ys=mse, xs=[theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "670fa556-9ef4-4c77-85f2-68390b7099eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.6322218775749207\n",
      "Epoch 200 MSE = 0.5727803111076355\n",
      "Epoch 300 MSE = 0.5585008263587952\n",
      "Epoch 400 MSE = 0.5490700006484985\n",
      "Epoch 500 MSE = 0.5422880053520203\n",
      "Epoch 600 MSE = 0.5373790860176086\n",
      "Epoch 700 MSE = 0.5338219404220581\n",
      "Epoch 800 MSE = 0.5312425494194031\n",
      "Epoch 900 MSE = 0.5293704867362976\n",
      "\n",
      "Best theta:\n",
      "[[ 2.06855249e+00]\n",
      " [ 7.74078071e-01]\n",
      " [ 1.31192386e-01]\n",
      " [-1.17845066e-01]\n",
      " [ 1.64778143e-01]\n",
      " [ 7.44078017e-04]\n",
      " [-3.91945094e-02]\n",
      " [-8.61356676e-01]\n",
      " [-8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(f\"\\nBest theta:\\n{best_theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b659d-72e4-4eb8-8837-702c2bfb68bc",
   "metadata": {},
   "source": [
    "<h3>Using a <code>GradientDescentOptimizer</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227b1ea-19dd-450f-bbf5-b0afb5b31a7d",
   "metadata": {},
   "source": [
    "The `GradientDescentOptimizer` is an optimization algorithm that iteratively adjusts the parameters (weights) of a model in the direction of the steepest descent of the loss function. It updates the parameters based on the gradients of the loss function with respect to the parameters, scaled by a learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e6478ca-52ed-46be-92ec-48f95b9aafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name=\"theta\"\n",
    ")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228476fa-e8bf-4f26-86ac-ec222c872ea6",
   "metadata": {},
   "source": [
    "Replace `gradients = ...` and `training_op = ...` with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "134799ca-8a35-4881-b4a3-472801ef3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)  # minimize the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0c611e0-7dcd-4075-968f-20ec6070d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.6322218775749207\n",
      "Epoch 200 MSE = 0.5727803111076355\n",
      "Epoch 300 MSE = 0.5585008263587952\n",
      "Epoch 400 MSE = 0.5490700006484985\n",
      "Epoch 500 MSE = 0.5422880053520203\n",
      "Epoch 600 MSE = 0.5373790860176086\n",
      "Epoch 700 MSE = 0.5338219404220581\n",
      "Epoch 800 MSE = 0.5312425494194031\n",
      "Epoch 900 MSE = 0.5293704867362976\n",
      "\n",
      "Best theta:\n",
      "[[ 2.06855249e+00]\n",
      " [ 7.74078071e-01]\n",
      " [ 1.31192386e-01]\n",
      " [-1.17845066e-01]\n",
      " [ 1.64778143e-01]\n",
      " [ 7.44078017e-04]\n",
      " [-3.91945094e-02]\n",
      " [-8.61356676e-01]\n",
      " [-8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(f\"\\nBest theta:\\n{best_theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36454042-8c89-44f1-b5c6-38a4b43fe121",
   "metadata": {},
   "source": [
    "<h3>Using a <code>MomentumOptimizer</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0663d2-6dbd-4d57-8a11-e9f2cdb48630",
   "metadata": {},
   "source": [
    "The `MomentumOptimizer` is an optimization algorithm that enhances the basic gradient descent method by incorporating momentum. It accumulates a weighted average of past gradients and uses this information to update the parameters (weights) of a model. This helps to accelerate convergence, especially in the presence of high curvature or noisy gradients. The momentum parameter controls the influence of past gradients on the parameter updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03e54467-563d-45c9-8c86-daf726be4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name=\"theta\"\n",
    ")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd7ef323-a43d-4a30-9430-7a8127e7fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set momentum parameter to 0.9, which controls the influence\n",
    "# of past gradients on the parameter updates\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eea511be-2d63-4d39-b268-c4a409df1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.5273160338401794\n",
      "Epoch 200 MSE = 0.5244147777557373\n",
      "Epoch 300 MSE = 0.5243281722068787\n",
      "Epoch 400 MSE = 0.5243218541145325\n",
      "Epoch 500 MSE = 0.5243210792541504\n",
      "Epoch 600 MSE = 0.5243210196495056\n",
      "Epoch 700 MSE = 0.5243209600448608\n",
      "Epoch 800 MSE = 0.5243209600448608\n",
      "Epoch 900 MSE = 0.5243209600448608\n",
      "\n",
      "Best theta:\n",
      "[[ 2.068558  ]\n",
      " [ 0.8296167 ]\n",
      " [ 0.11875112]\n",
      " [-0.26552212]\n",
      " [ 0.30569226]\n",
      " [-0.00450316]\n",
      " [-0.03932616]\n",
      " [-0.8998917 ]\n",
      " [-0.87054664]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(f\"\\nBest theta:\\n{best_theta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f3e28-98f5-41bf-9fc5-56b7453ee779",
   "metadata": {},
   "source": [
    "<h2>Feeding Data to the Training Algorithm</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083fb5e-72e2-4d02-9c41-c5ad478814b0",
   "metadata": {},
   "source": [
    "The `tf.placeholder()` function in TensorFlow is used to create a placeholder tensor. Placeholder tensors are used as input points for feeding actual data into a TensorFlow computational graph during the execution phase. They act as empty nodes that will be filled with actual data when a session runs the computational graph. Placeholders allow for dynamic data input, making TensorFlow models more flexible and adaptable to different datasets and scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba9dfd44-bb23-4d41-b394-633992407615",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "A = tf.placeholder(dtype=tf.float32, shape=(None, 3))  # None for any size measurement\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bcc2640-5399-4c29-bd8c-8146b57f70c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90345027-8f6e-4c56-94d9-d4370f7db6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a53db-8212-4159-9047-6c3eccfd380b",
   "metadata": {},
   "source": [
    "<h3>Mini-batch Gradient Descent</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c03bd8d-1f7f-4eef-964b-9328917a9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Set X and y as placeholders\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name=\"theta\"\n",
    ")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Define tha packet size and calculate the totla number of packets\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5d8a4-bfa7-4fe5-8d7a-a284e0c05eff",
   "metadata": {},
   "source": [
    "Finally, at runtime, one extracts the mini-batches one by one and provides the value of X and y through the feed_dict parameter when evaluating a node that depends on either of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60b91ace-d384-4c6f-bed2-e38e52ade348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0714476 ],\n",
       "       [ 0.8462012 ],\n",
       "       [ 0.11558535],\n",
       "       [-0.26835832],\n",
       "       [ 0.32982782],\n",
       "       [ 0.00608358],\n",
       "       [ 0.07052915],\n",
       "       [-0.87988573],\n",
       "       [-0.8634251 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "\n",
    "    return X_batch, y_batch\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b37178-0fd6-4923-9e86-e33ddfac708e",
   "metadata": {},
   "source": [
    "<h2>Saving and restoring a Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6a950-98ed-4936-818c-f7def6d664d8",
   "metadata": {},
   "source": [
    "`Saver()` in TensorFlow is a utility class used to save and restore TensorFlow models. It allows you to save the variables of a model to disk and later restore them during inference or further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e77d1c9d-e71b-492c-9ccf-4bbb760ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544267177581787\n",
      "Epoch 100 MSE = 0.6322218775749207\n",
      "Epoch 200 MSE = 0.5727803111076355\n",
      "Epoch 300 MSE = 0.5585008263587952\n",
      "Epoch 400 MSE = 0.5490700006484985\n",
      "Epoch 500 MSE = 0.5422880053520203\n",
      "Epoch 600 MSE = 0.5373790860176086\n",
      "Epoch 700 MSE = 0.5338219404220581\n",
      "Epoch 800 MSE = 0.5312425494194031\n",
      "Epoch 900 MSE = 0.5293704867362976\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(\n",
    "    tf.random_uniform(shape=[n + 1, 1], minval=-1.0, maxval=1.0, seed=42), name=\"theta\"\n",
    ")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Create a Saver to save TensorFlow model variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} MSE = {mse.eval()}\")\n",
    "            # Specify the path where the model variables will be saved and save them\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "    # Specify the path where the final model variables will be saved and save them\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f8e2292-2426-49f7-950c-cdf1e2ec3f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249e+00],\n",
       "       [ 7.74078071e-01],\n",
       "       [ 1.31192386e-01],\n",
       "       [-1.17845066e-01],\n",
       "       [ 1.64778143e-01],\n",
       "       [ 7.44078017e-04],\n",
       "       [-3.91945094e-02],\n",
       "       [-8.61356676e-01],\n",
       "       [-8.23479772e-01]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9aae3-27f9-4f84-a1cf-9081a850ce54",
   "metadata": {},
   "source": [
    "Restore model: you create a `Saver` object at the end of the build stage as before, but then call the `restore()` method of the `Saver` object at the beginning of the runtime stage instead of initializing variables using an initializing node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83f3a0cc-0c6d-4198-8831-1ac87c636c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f78c8dd6-f0e2-43ed-81c4-c338cf7e7680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaffa84-fe8f-4daf-a4e1-c84a735cdcdc",
   "metadata": {},
   "source": [
    "To utilizing a `saver` that loads and restores `theta` with a different identifier, such as 'weights':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a17c66c-2bfb-442a-a12a-e270da744e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({\"weights\": theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea851b-caf1-41c0-89ab-9ad22adbcd12",
   "metadata": {},
   "source": [
    "By default, the `saver` also stores the graph structure itself in a secondary file with the extension `.meta`. The function `tf.train.import_meta_graph()` can be utilized to recover the graph structure. This function imports the graph into the default graph and provides a `Saver` object that can subsequently be used to restore the graph state (i.e., the variable values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b96f8d5-a515-406f-8efe-392227135223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my_env/lib/python3.12/site-packages/tensorflow/python/client/session.py:1478: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n"
     ]
    }
   ],
   "source": [
    "# Start with an empty graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Import the graph structure from the meta file\n",
    "saver = tf.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")\n",
    "\n",
    "# Retrieve the variable named 'theta' from the imported graph\n",
    "theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")  # restore the graph's state\n",
    "    best_theta_restored = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760b18c-b801-4208-9b41-432dc690364c",
   "metadata": {},
   "source": [
    "This functionality enables the importation of a pretrained model without necessitating the corresponding Python code to construct the graph. This feature proves advantageous when continuously modifying and saving a model: a previously saved model can be loaded without the need to locate the version of the code that generated it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d7e1d-0098-4942-9503-697faf3f0a83",
   "metadata": {},
   "source": [
    "<h2>Visualization of the Graph and Learning Curves using TensorBoard</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead0c30-e2e3-4c5a-9285-20d18e8541af",
   "metadata": {},
   "source": [
    "TensorBoard is a great tool for visualizing TensorFlow graphs, training curves, and more. TensorFlow code typically writes various files to a log directory, and the TensorBoard server regularly reads these files to generate interactive visualizations. It can plot graphs, learning curves (i.e., how the loss evaluated on the training set or test set evolves as a function of the epoch number), profiling data to identify performance bottlenecks, and more. In short, it helps users keep track of everything. Here's the overall process:\n",
    "\n",
    "`TensorFlow writes logs to ===> log directory ===> TensorBoard reads data and displays visualizations`\n",
    "\n",
    "To visualize different graphs or learning curves for different training runs, it's important to organize the log files properly. Each graph or run should have its own log subdirectory. It's common to use a root log directory called `tf_logs` and create a subdirectory called `run-` followed by the current timestamp (or any other name preferred in your own code):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd37743-258e-428f-ac26-8c707f50f569",
   "metadata": {},
   "source": [
    "It's necessary to use a distinct log directory for each program run; otherwise, TensorBoard will combine statistics from various runs, resulting in compromised visualizations. To address this, it's recommended to incorporate a timestamp into the log directory name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f268065-64dc-4d7c-a96e-a37a7a55dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-20240412_114442/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"tf_logs/run-{now}/\"\n",
    "\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd648935-b10f-423a-a54a-0cd515636933",
   "metadata": {},
   "source": [
    "A function can be created to generate a subdirectory path whenever it's needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad625ddb-a252-41a2-8420-cd4676ed8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_subdir(run_id=None):\n",
    "    if run_id is None:\n",
    "        run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    return f\"tf_logs/run-{run_id}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062356f3-ae87-413e-ad59-05f785b87ace",
   "metadata": {},
   "source": [
    "`tf.summary.FileWriter()` is a utility class used to write summary data for TensorBoard visualization. It allows you to write various types of summary data, such as scalar values, histograms, and images, to event files that can be consumed by TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96ff2cdf-b40d-4369-a161-88a8f2030623",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(logdir=log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012696d-524e-4204-b2a9-531916e85313",
   "metadata": {},
   "source": [
    "Now the root log directory contains one subdirectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26271ac5-bcd0-4615-bad4-693225a00e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run-20240412_114442']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"tf_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c0f8d-8bb5-46e2-af25-71656191b116",
   "metadata": {},
   "source": [
    "And this subdirectory contains only one log file (called `tfevents` file) for the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f3eb8ba-4e10-4255-b1a9-1e26b397ae95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['events.out.tfevents.1712915082.Ivans-MBP.fritz.box']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350490d9-8026-4a74-a94b-85c3555d0afe",
   "metadata": {},
   "source": [
    "In order to ensure that the actual graph data is properly written to disk, it's necessary to call `flush()` or `close()` on the `FileWriter`. This action is crucial as the data may still be in the operating system's file cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ce8a81c-c58c-40ef-a80c-1d72e3ab6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467c3d4-0614-4084-a3a2-0eacdc031904",
   "metadata": {},
   "source": [
    "In order to start TensorBoard, it must be initiated as a web server in a separate process. One approach is to execute the `tensorboard` command in a terminal window. Alternatively, the `%tensorboard` Jupyter extension can be utilized, which not only launches TensorBoard but also facilitates viewing its user interface directly within Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "715a3e25-ad3c-4398-abab-03c0685bf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56998ac0-f3e6-4afb-886e-35cfefac075d",
   "metadata": {},
   "source": [
    "The `%tensorboard` extension to start the TensorBoard server. Must point to the root log directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29e6d2a2-a5ff-4a23-9555-becf424121d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4e703836201cc595\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4e703836201cc595\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8400c-7859-443d-b61e-4d676dc0cc4d",
   "metadata": {},
   "source": [
    "To simplify this process, a save_graph() function can be created. This function automatically generates a new log subdirectory and saves the specified graph (by default tf.get_default_graph()) to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1540b8d-8e19-4556-9a81-1249cdb2ac86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-20240412_114453/'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_graph(graph=None, run_id=None):\n",
    "    if graph is None:\n",
    "        graph = tf.get_default_graph()\n",
    "    log_dir = make_log_subdir(run_id=run_id)\n",
    "    file_writer = tf.summary.FileWriter(logdir=log_dir, graph=graph)\n",
    "    file_writer.close()\n",
    "    return log_dir\n",
    "\n",
    "\n",
    "save_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb557b9d-085b-4534-9895-415e2faf2150",
   "metadata": {},
   "source": [
    "<h3>Visualizing Learning Curves</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cd4db86-8c0b-4303-b9f2-7ba2eb298ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "log_dir = make_log_subdir()\n",
    "\n",
    "mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "file_writer = tf.summary.FileWriter(logdir=log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43fd8bf2-449b-456e-a50a-56cafe83c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(\n",
    "                epoch=epoch, batch_index=batch_index, batch_size=batch_size\n",
    "            )\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96804360-5d10-426f-af14-213445c22576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1198488 ],\n",
       "       [ 0.40280202],\n",
       "       [ 0.5302975 ],\n",
       "       [ 0.50325125],\n",
       "       [-0.06576284],\n",
       "       [ 0.24595782],\n",
       "       [-0.63472825],\n",
       "       [-0.7215738 ],\n",
       "       [-0.39073238]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6993187-92f8-4e78-b408-734754f99e7e",
   "metadata": {},
   "source": [
    "Let's examine TensorBoard. One should attempt to navigate to the SCALARS tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9972ea68-fc5a-4437-bbfe-82ead3d3863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21949), started 0:00:01 ago. (Use '!kill 21949' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7089f9351eac5903\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7089f9351eac5903\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b893f-34b7-4e70-a1c4-3d5e3be3dc16",
   "metadata": {},
   "source": [
    "<h2>Name Scopes</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ed6f8-4098-4b23-9dcb-da0bcbcd0d75",
   "metadata": {},
   "source": [
    "Name scopes provide a way to organize operations within a computational graph. They group related operations together, enabling clearer organization, hierarchical structuring, and easier visualization and debugging of complex models. Scoped names automatically prefix operations, aiding in identification and management of the computational graph's complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d34a242d-4578-4255-9fb8-0c9d639809e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0130dba-0897-4038-b587-5d644c896511",
   "metadata": {},
   "source": [
    "Define the operations `error` and `mse` within the namespace called \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dca9b4d2-c9f9-411f-9f1f-0e9157339de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss') as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c20d7591-dfa0-47a2-9c3e-cab7607b15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "log_dir = make_log_subdir()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir=log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82fc337b-a514-4dde-9d8a-d5fd508904ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.070016  ]\n",
      " [ 0.8204561 ]\n",
      " [ 0.1173173 ]\n",
      " [-0.22739051]\n",
      " [ 0.3113402 ]\n",
      " [ 0.00353193]\n",
      " [-0.01126994]\n",
      " [-0.91643935]\n",
      " [-0.8795008 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush()\n",
    "file_writer.close()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30729592-3c5f-4e5d-ac04-6a486972dfa6",
   "metadata": {},
   "source": [
    "The name of each operation defined within the space is now prefixed with `loss/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94c4c90b-c9aa-4984-82a2-2f909865701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5db90295-ed57-4131-9e9c-353801233617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e1231-9be8-4382-9fb3-25dfd64532a3",
   "metadata": {},
   "source": [
    "<h2>Modularity</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e57fc1d5-973a-42a6-b029-c2df867d4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name='weights1')\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name='weights2')\n",
    "\n",
    "b1 = tf.Variable(0.0, name='bias1')\n",
    "b2 = tf.Variable(0.0, name='bias2')\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name='z1')\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name='z2')\n",
    "\n",
    "relu1 = tf.maximum(z1, 0.0, name='relu1')\n",
    "relu2 = tf.maximum(z2, 0.0, name='relu2')\n",
    "\n",
    "output = tf.add(relu1, relu2, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ba17d-6dbd-4c97-9b1a-f405a9767806",
   "metadata": {},
   "source": [
    "ReLU (Rectified Linear Unit) is an activation function commonly used for introducing non-linearity into the model. It computes the output as the maximum of 0 and the input value, effectively thresholding negative values to zero while leaving positive values unchanged. ReLU is simple and computationally efficient, and it helps prevent the vanishing gradient problem during training by allowing for faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6b4fb-2212-4038-b3d3-1a55ce34b5d6",
   "metadata": {},
   "source": [
    "Using a function to build the ReLUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "753d9553-7c7c-4e84-a484-eed3449a8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "    b = tf.Variable(0.0, name='bias')\n",
    "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "    return tf.maximum(z, 0.0, name='relu')\n",
    "\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ec091cd-9564-44dc-ae63-1582e1cdbec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-relu1/'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_graph(run_id='relu1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7907d882-8e5f-4188-b20f-15e2fdcc381d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cbd85174b62c000c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cbd85174b62c000c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir 'tf_logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b31996-0f16-44b4-87c6-d22bdde16309",
   "metadata": {},
   "source": [
    "Using a function to build the ReLUs with a name scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1340003-6cb9-47e9-86cc-3521be8f2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope('relu'):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "        b = tf.Variable(0.0, name='bias')\n",
    "        z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "        return tf.maximum(z, 0.0, name='relu')\n",
    "\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d470f94-807d-4bf0-9768-3667dbf0dc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-relu2/'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_graph(run_id='relu2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0cf913ac-5e51-49f3-a57a-da13cca8f4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 21952), started 0:00:00 ago. (Use '!kill 21952' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5ebd1679c3d55ebb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5ebd1679c3d55ebb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir 'tf_logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a4b23-6091-42b3-a9fd-2067a0453734",
   "metadata": {},
   "source": [
    "<h2>Sharing Variables</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e238e90-d779-4c25-bb96-c1795d8aed5e",
   "metadata": {},
   "source": [
    "Sharing a `threshold` variable is a classic way, by defining it outside of the `relu()` function the passing it as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "457e6d8a-3ce7-4cea-8aec-97ea0567ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def relu(X, threshold):\n",
    "    with tf.name_scope('relu'):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "        b = tf.Variable(0.0, name='bias')\n",
    "        z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "        return tf.maximum(z, threshold, name='max')\n",
    "\n",
    "\n",
    "threshold = tf.Variable(0.0, name='threshold')\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09ceee-05c4-44d6-bd04-ca80fb7753a1",
   "metadata": {},
   "source": [
    "Shared variable as an attribute of the `relu()` function at the first call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ab10eed-f678-40d7-9e32-71413d923ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope('relu'):\n",
    "        if not hasattr(relu, 'thershold'):\n",
    "            relu.threshold = tf.Variable(0.0, name='threshold')\n",
    "        w_shape = int(X.get_shape()[1]), 1\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "        b = tf.Variable(0.0, name='bias')\n",
    "        z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "        return tf.maximum(z, relu.threshold, name='max')\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe81b9-d492-410b-82b3-58b50fd7e70a",
   "metadata": {},
   "source": [
    "The TensorFlow library suggests using the `get_variable()` function to create a shared variable if it does not yet exist, or reuse it if it already exists. The behavior (create or reuse) is controlled by the `variable_scope()` attribute of the current variable space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2ac1ae1-66ea-468c-947f-47ee1e93e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "with tf.variable_scope('relu'):\n",
    "    threshold = tf.get_variable(\n",
    "        name='threshold', shape=(), initializer=tf.constant_initializer(0.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234b477-3263-440d-b02c-7b4c563e7406",
   "metadata": {},
   "source": [
    "To reuse a variable, set the `reuse` attribute of the variable space to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2f2a790-12c3-43e7-b6a7-b989381b374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('relu', reuse=True):\n",
    "    threshold = tf.get_variable('threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d3c99-af77-4591-a497-03666d4df0fa",
   "metadata": {},
   "source": [
    "Alternatively, set the `reuse` attribute to `True` within a block by calling the `reuse_variables()` method of the variable space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2b4c04c-80e1-421f-8823-a7b549424bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('relu') as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable('threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa49629-327b-42f9-a9c6-7c432a17e4fc",
   "metadata": {},
   "source": [
    "The `relu()` function with the `threshold` variable without needing to pass it as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c629d17-3b58-44a8-9d7b-c4c2e68c7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable('threshold')  # reuse an existing variable\n",
    "        w_shape = int(X.get_shape()[1]), 1\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "        b = tf.Variable(0.0, name='bias')\n",
    "        z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "        return tf.maximum(z, threshold, name='max')\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "with tf.variable_scope('relu'):  # create variable\n",
    "    threshold = tf.get_variable(\n",
    "        name='threshold', shape=(), initializer=tf.constant_initializer(0.0)\n",
    "    )\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87eccdc0-451f-4ee6-a21e-d43e126d9a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-relu3/'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_graph(run_id='relu3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f5459ee-73f4-4a65-a115-0e43cb4b5339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 21952), started 0:00:01 ago. (Use '!kill 21952' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-823659355e4a9076\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-823659355e4a9076\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir 'tf_logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de55aa-5069-40be-9786-cba994f8d35d",
   "metadata": {},
   "source": [
    "The `threshold` variable must be defined outside the `relu()` function, where all other ReLU code resides. </br>\n",
    "The following code creates the `threshold` variable inside the `relu()` function on its first call, and reuses it on subsequent calls. Now the `relu()` function doesn't have to worry about namespaces or variable separation: it simply calls the `get_variable()` method, which will create or reapply the threshold variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "26efe412-941d-4536-888a-72defe5cf631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\n",
    "        name='threshold', shape=(), initializer=tf.constant_initializer(0.0)\n",
    "    )\n",
    "    w_shape = int(X.get_shape()[1]), 1\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "    b = tf.Variable(0.0, name='bias')\n",
    "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "    return tf.maximum(z, threshold, name='max')\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "# The `relu()` function is called five times, ensuring that `reuse=False`\n",
    "# is set for the first call and `reuse=True` for all others\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope('relu', reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5120c667-6f54-4720-88dd-afa7a1e6bc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-relu4/'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_graph(run_id='relu4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "feadb391-1090-4985-bb51-c225d9f2f72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 21952), started 0:00:01 ago. (Use '!kill 21952' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e918129bbf989e2f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e918129bbf989e2f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir 'tf_logs'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
